# Best Link for Best Topic

This is a simple link sharing `readme` for best short topics on internet. 
You can contribute. Please send me a pull request. 



# Machine Learning
- [Activation Functions](https://www.youtube.com/watch?v=9vB5nzrL4hY)
- [RRN, LSTM Intro](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
  - [LSTM More](https://towardsdatascience.com/understanding-lstm-and-its-quick-implementation-in-keras-for-sentiment-analysis-af410fd85b47)
  - [LSTM Core](https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4)
  
- [About CNN](http://brohrer.github.io/how_convolutional_neural_networks_work.html)
  - [CNN Layer Calculation](https://towardsdatascience.com/understanding-and-calculating-the-number-of-parameters-in-convolution-neural-networks-cnns-fc88790d530d)
- [Attention](https://www.youtube.com/watch?v=W2rWgXJBZhU&pbjreload=10)
  - [Attention Article](https://medium.com/syncedreview/a-brief-overview-of-attention-mechanism-13c578ba9129)
  - [Attention Tensorflow](http://akosiorek.github.io/ml/2017/10/14/visual-attention.html)
- [Flattening](https://www.superdatascience.com/convolutional-neural-networks-cnn-step-3-flattening/)
- [Dropout](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5)
- [Gradient](https://youtu.be/tIpKfDc295M)
- [Pooling](http://deeplearning.stanford.edu/tutorial/supervised/Pooling/)
- [Probability Distribution](https://youtu.be/cqK3uRoPtk0?t=1)
- [LSTM vs Bi-LSTM](https://stackoverflow.com/questions/43035827/whats-the-difference-between-a-bidirectional-lstm-and-an-lstm)
- [seq2seq LSTM](https://towardsdatascience.com/seq2seq-model-in-tensorflow-ec0c557e560f)
  - [seq2seq LSTM](https://www.analyticsvidhya.com/blog/2018/03/essentials-of-deep-learning-sequence-to-sequence-modelling-with-attention-part-i/)
  - [seq2seq Keras model for Translation](https://nextjournal.com/gkoehler/machine-translation-seq2seq-cpu)
  - [Seq2Seq Keras(Encoder Decoder)](https://towardsdatascience.com/nlp-sequence-to-sequence-networks-part-2-seq2seq-model-encoderdecoder-model-6c22e29fd7e1)
- [Tensorflow Basics](https://www.easy-tensorflow.com/tf-tutorials/basics)
- [Policy Gradient](https://medium.freecodecamp.org/an-introduction-to-policy-gradients-with-cartpole-and-doom-495b5ef2207f)
- [Accuracy, Precision, Recall & F1 Score](https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/)
  - [Confusion Matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62)
- [Optimization Algorithm](https://towardsdatascience.com/types-of-optimization-algorithms-used-in-neural-networks-and-ways-to-optimize-gradient-95ae5d39529f)
- [Word Embedding](https://towardsdatascience.com/word-embedding-with-word2vec-and-fasttext-a209c1d3e12c)
- [Perceptron](https://towardsdatascience.com/what-the-hell-is-perceptron-626217814f53)
- [Step by Step **Backpropagation**](https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/)
- [Install multiple cuda version at same machine](https://blog.kovalevskyi.com/multiple-version-of-cuda-libraries-on-the-same-machine-b9502d50ae77)
- [librosa](https://medium.com/@patrickbfuller/librosa-a-python-audio-libary-60014eeaccfb)

# Informative Blog
- [https://ruder.io/](https://ruder.io/)
- [https://colah.github.io/](https://colah.github.io/)


# Papers and Codes
- [Papers with Code](https://paperswithcode.com/)
- [nlpprogress](https://nlpprogress.com/)


# Python
- [Built-in Exceptions](https://docs.python.org/3/library/exceptions.html#concrete-exceptions)
  - [Example and Explanation](https://realpython.com/python-exceptions/)
- [Python Numpy Tutorial](http://cs231n.github.io/python-numpy-tutorial/)
- [ _ ](https://hackernoon.com/understanding-the-underscore-of-python-309d1a029edc)
- [ **, ^, %, // ](https://stackoverflow.com/questions/15193927/what-do-these-operators-mean)
- [Lambda](https://www.w3schools.com/python/python_lambda.asp)
- [\__init\__ & self](https://micropyramid.com/blog/understand-self-and-__init__-method-in-python-class/)
- [pandas in 10 minutes](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html)
- [Python tricks](https://hackernoon.com/python-tricks-101-2836251922e0)

# Mathematics
- [Calculus](https://www.mathway.com/Calculus)
- [wolframalpha](https://www.wolframalpha.com/)
- [Math Stack-Exchange](https://math.stackexchange.com/)


# Papers
## Machine Learning
  - [Attention](https://nlp.stanford.edu/pubs/emnlp15_attn.pdf)
  - [LSTM](https://www.bioinf.jku.at/publications/older/2604.pdf)
  - [Overview of Gradient Descent Optimization Algorithm](https://arxiv.org/pdf/1609.04747.pdf)
  - [Pointer Networks](https://arxiv.org/pdf/1506.03134.pdf)
  - [Gated Recurrent Unit](https://arxiv.org/pdf/1412.3555.pdf)
  - [DRAW: A Recurrent Neural Network For Image Generation](https://arxiv.org/pdf/1502.04623.pdf)
  - [GAN:Generative Adversarial Network](https://arxiv.org/pdf/1406.2661.pdf)
  - [Adam](https://arxiv.org/pdf/1412.6980.pdf)
  - [FastText](https://arxiv.org/abs/1607.04606)
  - [BERT](https://arxiv.org/pdf/1810.04805.pdf)
  
## Awesome Curated List
- [Awesome NLP](https://github.com/keon/awesome-nlp)
- [Awesome GAN](https://github.com/nashory/gans-awesome-applications)
- [Awesome Bengali](https://github.com/banglakit/awesome-bangla)
  
  
# State of Art Deep Learning
  - [Question Answer](https://aclweb.org/aclwiki/Question_Answering_(State_of_the_art))
  - [Paraphrasing](https://aclweb.org/aclwiki/Paraphrase_Identification_(State_of_the_art))
  - [POS Tagging](https://aclweb.org/aclwiki/POS_Tagging_(State_of_the_art))
  


